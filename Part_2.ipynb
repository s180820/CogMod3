{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualising the data\n",
    "# • Plot a probability density histogram for each type of stimulus. This height of each bar\n",
    "# should be the proportion of responses divided by the width of the column.\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (20,10)\n",
    "\n",
    "# Load the data\n",
    "data_path= \"Data/Part_2/\"\n",
    "dfs = []\n",
    "for file in glob.glob('Data/Part_2/*.txt'):\n",
    "  dfs.append(pd.DataFrame(np.loadtxt(file)))\n",
    "df_all = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first row of the array contains response counts for the auditory stimuli. The columns of\n",
    "# the first row indicate the specific auditory stimulus ranging from very similar to a ’b’ in the\n",
    "# first column to very similar to a ’d’ in the last column. Likewise, the second row contains\n",
    "# response counts to the visual stimulus ranging from very similar to a ’b’ to very similar to a\n",
    "# ’d’. Rows 3-7 contains response counts for the audiovisual stimuli. Rows indicate the visual\n",
    "# component of the stimulus ranging from very similar to a ’b’ (row 3) to very similar to a ’d’\n",
    "# (row 7). Columns indicate the auditory component of the stimulus ranging from very similar\n",
    "# to a ’b’ (column 1) to very similar to a ’d’ (column 5).\n",
    "# df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split df_all into 5 dfs\n",
    "df_1 = df_all.iloc[0:7,0:5]\n",
    "df_2 = df_all.iloc[7:14,0:5]\n",
    "df_3 = df_all.iloc[14:21,0:5]\n",
    "df_4 = df_all.iloc[21:28,0:5]\n",
    "df_5 = df_all.iloc[28:35,0:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the early strong fusion model\n",
    "\n",
    "def early_strong_fusion(data):\n",
    "    # our code here\n",
    "    return model\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1     2     3     4\n",
       "0   0.0   2.0   4.0  24.0  24.0\n",
       "1   0.0  17.0  24.0  24.0  24.0\n",
       "2   0.0   0.0   0.0  10.0  14.0\n",
       "3   4.0   8.0   7.0  20.0  22.0\n",
       "4   9.0  15.0  19.0  24.0  24.0\n",
       "5  14.0  17.0  22.0  24.0  24.0\n",
       "6  14.0  19.0  23.0  24.0  24.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "means_ini = [1,2,3,4,5]\n",
    "# means_ini = [1,2,3,4,5]\n",
    "sigma_a_ini = df_1[0].std(axis=0).mean()\n",
    "sigma_v_ini = df_1[1].std(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the combined distributions\n",
    "def combined_distributions(means_est, sigma_a_ini, sigma_v_ini, data):\n",
    "    w_a = (sigma_v_ini)**2 / ((sigma_v_ini)**2 + (sigma_a_ini)**2)\n",
    "    \n",
    "    # 5 by 5 matrix of 0 \n",
    "    means_av_matrix= np.zeros((5,5))\n",
    "    print(means_av_matrix)\n",
    "    # for i in range(5):\n",
    "    #     for j in range(5):\n",
    "    #         mean_av = w_a * (means_est[i]) + (1 - w_a) * (means_est[j+2])\n",
    "    #         np.append(means_av_matrix[i,j], mean_av, axis=0)\n",
    "    # sigma_av = ((sigma_a_ini)**2 * (sigma_v_ini)**2) / ((sigma_a_ini)**2 + (sigma_v_ini)**2)\n",
    "\n",
    "\n",
    "    # return [means_av_matrix, sigma_av] \n",
    "    return means_av_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_distributions(means_ini, sigma_a_ini, sigma_v_ini, df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'means_av_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Dokumenter\\Dokumenter\\Git_Projects\\CogMod3\\Part_2.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Dokumenter/Dokumenter/Git_Projects/CogMod3/Part_2.ipynb#ch0000014?line=0'>1</a>\u001b[0m means_av_matrix[\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'means_av_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# use the binomial pdf with the normal cdf inside \n",
    "# look at the psycometric function for the first assignment homework \n",
    "err - stats.binomial.pdf(data0[i], loc=means[i], scale=scale[i]).sum() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit an early Bayesian Causal Inference model (BCI)\n",
    "\n",
    "def early_BCI(data):\n",
    "    # our code here\n",
    "    return model\n",
    "\n",
    "###### is this just the same as we did in part 1? The BCI model? ######"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('katrine_personal_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23b47e8941e9532a227126a88d0aed60e854f3b3d5618484cace29efe7d4fdfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
